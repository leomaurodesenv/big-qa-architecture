{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomaurodesenv/big-qa-architecture/blob/main/jupyter/3_Document_Reader_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Ls6eJuZOJU"
      },
      "source": [
        "# Document Reader Experiments\n",
        "\n",
        "In Question Answering (QA), queries are run over several documents to extract an answer to user questions, consisting of two main steps: (1) Document Retriever — retrieve the most useful documents that may contain the answer to a given question; (2) Document Reader — a machine reader carefully examines the retrieved documents and frame an answer.\n",
        "\n",
        "In this Jupyter Notebook, we focused on the Document Reader experiments, motivated by the fact that using a good Reader (higher F1) produces a better and more concise response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIJkSiBZSEE"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "\n",
        "Packages installation and setups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au67ibLgZVCb"
      },
      "source": [
        "### Run Configuration\n",
        "\n",
        "Choose the dataset and the Document Reader algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LalmjrULZGq7"
      },
      "outputs": [],
      "source": [
        "import enum\n",
        "\n",
        "class Dataset(enum.Enum):\n",
        "    '''Dataset options'''\n",
        "    SQuAD = 1\n",
        "    AdvQA = 2\n",
        "    DuoRC = 3\n",
        "    QASports = 4\n",
        "\n",
        "class DocReader:\n",
        "    '''Document Reader options'''\n",
        "    BERT    = \"deepset/bert-base-uncased-squad2\"\n",
        "    RoBERTa = \"deepset/roberta-base-squad2\"\n",
        "    MiniLM  = \"deepset/minilm-uncased-squad2\"\n",
        "    DistilBERT = \"distilbert-base-uncased-distilled-squad\"\n",
        "    FineDistilBERT = \"laurafcamargos/distilbert-qasports-basket-small\"\n",
        "    ELECTRA = \"deepset/electra-base-squad2\"\n",
        "\n",
        "class Sports:\n",
        "    BASKETBALL = \"basketball\"\n",
        "    FOOTBALL = \"football\"\n",
        "    SOCCER = \"soccer\"\n",
        "    ALL = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbqKXjSMcezM"
      },
      "outputs": [],
      "source": [
        "# run configuration\n",
        "NUM_K      = 1 # always = 1\n",
        "DATASET    = Dataset.QASports\n",
        "DOC_READER = DocReader.RoBERTa\n",
        "SPORT      = Sports.SOCCER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6wDDSutdwAc"
      },
      "source": [
        "### Package Installation\n",
        "\n",
        "Install Haystack and HuggingFace packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1999MLVdt90",
        "outputId": "bb6c70fd-6033-43a1-cf1f-af8d9ea075b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Feb 27 11:26:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check if you have a GPU running\n",
        "# The code runs in CPU as well\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsRUap4UdxOe",
        "outputId": "2b9d29b2-8e11-4f9a-8101-173b0c7972ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.7/763.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\n",
            "wandb 0.19.7 requires pydantic<3,>=2.6, but you have pydantic 1.10.21 which is incompatible.\n",
            "langchain-core 0.3.37 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
            "albumentations 2.0.4 requires pydantic>=2.9.2, but you have pydantic 1.10.21 which is incompatible.\n",
            "google-genai 0.8.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\n",
            "langchain 0.3.19 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.12.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface_hub==0.25.0\n",
            "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.25.0) (2025.1.31)\n",
            "Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "Successfully installed huggingface_hub-0.25.0\n",
            "Huggingface installation with success!\n",
            "Collecting mmh3\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mmh3\n",
            "Successfully installed mmh3-5.1.0\n",
            "Extra installation with success!\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "# Install the Haystack\n",
        "!pip install farm-haystack==1.26.2 --quiet\n",
        "\n",
        "# Install Huggingface\n",
        "!pip install transformers==4.39.3 --quiet\n",
        "!pip install sentence-transformers==2.2.2 --quiet\n",
        "!pip install huggingface_hub==0.25.0\n",
        "!echo \"Huggingface installation with success!\"\n",
        "# Extra\n",
        "!pip install mmh3\n",
        "!pip install datasets\n",
        "!pip install rapidfuzz\n",
        "!echo \"Extra installation with success!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "183EAI5bd2Q2"
      },
      "source": [
        "### Logging\n",
        "\n",
        "We configure how logging messages should be displayed and which log level should be used before importing Haystack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYx-oJJKdyqE"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# Setup Haystack logging format\n",
        "logging.basicConfig(format=\"%(levelname)s - %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3nN5vbehUEV"
      },
      "source": [
        "---\n",
        "## Dataset\n",
        "\n",
        "Importing and download the respective dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ2TYqhwhW29"
      },
      "source": [
        "### Abstract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhwInJGFhUzd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "class AbstactDataset(metaclass = ABCMeta):\n",
        "    '''Abstract dataset class'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.raw_dataset = self.download()\n",
        "        self.df_dataset = self._transform_df()\n",
        "        print(f\"## {self.name} ##\")\n",
        "        print(self.raw_dataset)\n",
        "\n",
        "    def _transform_df(self):\n",
        "        '''Transform dataset in a pd.DataFrame'''\n",
        "        return pd.DataFrame(self.raw_dataset)\n",
        "\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def name(self):\n",
        "        '''Dataset name'''\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def download(self):\n",
        "        '''Download the dataset'''\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_documents(self):\n",
        "        '''Get the unique documents to store in the Document Store'''\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_validation(self):\n",
        "        '''Get the validation set'''\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-I5zhpEVQHW"
      },
      "source": [
        "### SQuaD Dataset\n",
        "\n",
        "https://huggingface.co/datasets/squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpYws_9qIbAZ",
        "outputId": "9d011327-7b0f-4b73-8c97-3bd4503cdc16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by manually setting the environment variable HAYSTACK_TELEMETRY_ENABLED as described for different operating systems in the [documentation page](https://docs.haystack.deepset.ai/docs/telemetry#how-can-i-opt-out). More information at [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry).\n"
          ]
        }
      ],
      "source": [
        "import mmh3\n",
        "from datasets import load_dataset\n",
        "from haystack.schema import Label, Document, Answer\n",
        "from haystack.schema import EvaluationResult, MultiLabel\n",
        "\n",
        "class SQuadDataset(AbstactDataset):\n",
        "    '''SQuaD Dataset'''\n",
        "    name = \"SQuaD Dataset\"\n",
        "    _columns = {\n",
        "        \"title\": \"title\",\n",
        "        \"document\": \"context\",\n",
        "        \"question\": \"question\",\n",
        "    }\n",
        "    _metadata = {\n",
        "        \"dataset_id\": \"id\"\n",
        "    }\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"squad\", split=\"validation\")\n",
        "        return dataset\n",
        "\n",
        "    def get_documents(self):\n",
        "        # Remove duplicated contents\n",
        "        cc = self._columns\n",
        "        dataset_name = f\"{self.name}\"\n",
        "        df = self.df_dataset\n",
        "        df = df.drop_duplicates(subset=[cc[\"title\"], cc[\"document\"]], keep=\"first\")\n",
        "\n",
        "        # Create Haystack Document objects\n",
        "        list_docs = []\n",
        "        for _, row in df.iterrows():\n",
        "            document_id = mmh3.hash128(row[cc[\"document\"]], signed=False)\n",
        "            doc_metadata = {k: row[v] for k,v in self._metadata.items()}\n",
        "            doc_metadata[\"title\"] = row[cc[\"title\"]]\n",
        "            doc_metadata[\"dataset_name\"] = dataset_name\n",
        "            doc = Document(\n",
        "                id=document_id,\n",
        "                content_type=\"text\",\n",
        "                content=row[cc[\"document\"]],\n",
        "                meta=doc_metadata\n",
        "            )\n",
        "            list_docs.append(doc)\n",
        "        return list_docs\n",
        "\n",
        "    def _get_answers(self, data):\n",
        "        # Get question answer\n",
        "        return data[\"answers\"][\"text\"]\n",
        "\n",
        "    def get_validation(self):\n",
        "        # Get dataset info\n",
        "        cc = self._columns\n",
        "        df = self.df_dataset\n",
        "        _self = self\n",
        "\n",
        "        # Create Haystack labels\n",
        "        eval_labels = []\n",
        "        for _, row in df.iterrows():\n",
        "            document_id = mmh3.hash128(row[cc[\"document\"]], signed=False)\n",
        "            doc_label = MultiLabel(labels=[\n",
        "                Label(\n",
        "                    query = row[cc[\"question\"]],\n",
        "                    answer = Answer(answer = answer, type = \"extractive\"),\n",
        "                    document = Document(\n",
        "                        id=document_id,\n",
        "                        content_type=\"text\",\n",
        "                        content=row[cc[\"document\"]],\n",
        "                    ),\n",
        "                    is_correct_answer=True,\n",
        "                    is_correct_document=True,\n",
        "                    origin=\"gold-label\",\n",
        "                )\n",
        "                for answer in _self._get_answers(row)\n",
        "            ])\n",
        "            eval_labels.append(doc_label)\n",
        "        return eval_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwTiflFj4rzz"
      },
      "source": [
        "### AdversarialQA Dataset\n",
        "\n",
        "https://huggingface.co/datasets/adversarial_qa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBeOsUVq4rg_"
      },
      "outputs": [],
      "source": [
        "class AdversarialQADataset(SQuadDataset):\n",
        "    '''AdversarialQA Dataset'''\n",
        "    name = \"AdversarialQA Dataset\"\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"adversarial_qa\", \"adversarialQA\", split=\"validation\")\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9wk72kP69cW"
      },
      "source": [
        "### DuoRC Dataset\n",
        "\n",
        "https://huggingface.co/datasets/duorc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHHyNQ8j7B-D"
      },
      "outputs": [],
      "source": [
        "class DuoRCDataset(SQuadDataset):\n",
        "    '''DuoRC  Dataset'''\n",
        "    name = \"DuoRC Dataset\"\n",
        "    _columns = {\n",
        "        \"title\": \"title\",\n",
        "        \"document\": \"plot\",\n",
        "        \"question\": \"question\",\n",
        "    }\n",
        "    _metadata = {\n",
        "        \"dataset_id\": \"question_id\"\n",
        "    }\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"duorc\", \"SelfRC\", split=\"validation\")\n",
        "        return dataset\n",
        "\n",
        "    def _transform_df(self):\n",
        "        '''Transform dataset in a pd.DataFrame'''\n",
        "        df = pd.DataFrame(self.raw_dataset)\n",
        "        # Get questions with answer\n",
        "        return df[~df[\"no_answer\"]]\n",
        "\n",
        "    def _get_answers(self, data):\n",
        "        # Get question answer\n",
        "        return data[\"answers\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icz9gWMA7njZ"
      },
      "source": [
        "### QASports Dataset\n",
        "\n",
        "https://huggingface.co/datasets/PedroCJardim/QASports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM5Dejhd7mVt"
      },
      "outputs": [],
      "source": [
        "class QASportsDataset(SQuadDataset):\n",
        "    '''QASports  Dataset'''\n",
        "    name = \"QASports Dataset\"\n",
        "    _columns = {\n",
        "        \"title\": \"context_title\",\n",
        "        \"document\": \"context\",\n",
        "        \"question\": \"question\",\n",
        "    }\n",
        "    _metadata = {\n",
        "        \"dataset_id\": \"id_qa\"\n",
        "    }\n",
        "\n",
        "    def __init__(self, sport=None):\n",
        "        self.sport = sport\n",
        "        super().__init__()\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"PedroCJardim/QASports\", self.sport, split=\"validation\") if self.sport is not None \\\n",
        "                  else load_dataset(\"PedroCJardim/QASports\", split=\"validation\")\n",
        "        return dataset\n",
        "\n",
        "    def _transform_df(self):\n",
        "        '''Transform dataset in a pd.DataFrame'''\n",
        "        df = pd.DataFrame(self.raw_dataset)\n",
        "        # Get questions with answer\n",
        "        df[\"answer\"] = df[\"answer\"].astype(str).apply(eval)\n",
        "        mask = df[\"answer\"].apply(lambda x: True if isinstance(x, dict) and x.get(\"text\", \"\") != \"\" else False)\n",
        "        return df[mask]\n",
        "\n",
        "    def _get_answers(self, data):\n",
        "        # Get question answer\n",
        "        return [data[\"answer\"][\"text\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGC6aaS1VU3d"
      },
      "source": [
        "### Download the dataset\n",
        "\n",
        "Get the dataset and store the documents in the Document Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "25b9b31146fa4e0eb95b034ca7c607ca",
            "6ea0d181b9a540fc8cc729b2ef403834",
            "c7e9fea14762476aa2728ab68eae9491",
            "c93f600e6f8a46a9a8b4eee68b1544ff",
            "bb72e2fdca80427aae277a5235baa3d0",
            "ad905b37ff7f4c5ab64d571e822c5dcb",
            "9aa7e15974f74c00be51dde405023502",
            "7c3d7a9f79d449f5a367a273e4d5dab7",
            "f852aceef5cd429eb0e0ff660bef99c7",
            "f4360f8966234b39af0333e6e6660703",
            "3c9460f0658148a888ad7265fd28c374",
            "6c480c76f55e4032950711c34d87fd3c",
            "04e0bb63cdf040cbb5ab0443fbe17c96",
            "d36a52a4d97740b48cee7e39cd0a4eac",
            "1b4ac3b0e2b54ac397e95aa4c9da9a3c",
            "c86d153c6b924d96bdd24e5d414cb52e",
            "11a0d6a59f6241ed920b49c57a7136aa",
            "9f9eded686894d9d8a890b3d68db99d1",
            "99be9e05fd7640e7ab7fea1dcaabf3c2",
            "916b80865a774effa2bb2f8de0d2f8f0",
            "a9ceca9067e943738b4128c1d17d0793",
            "b6839f265ef24761b754471c3a8fb209",
            "dd82c4bbcbec46b583b421fd810591ff",
            "a8188b62a3f44a5381e8f4753d27bd74",
            "1f14607562e8485badb5a052721a221b",
            "554b8b933c624e31a8b31f0919e91844",
            "d568b297547f439396ef0054339ea15f",
            "5a05156d706844f1ad67b656ee3692fd",
            "b5d6dfb3fd2447f4b3391bea51ae5b5e",
            "69e18063b84c47f3993489c8c9233503",
            "ad5bd23c565b415ba96e908e08b6defa",
            "f019647c68384ee2a8be17776816cde6",
            "37be89b7575448c6a581141a1563ac1f",
            "1b1debe136e0475aaf33532d12bf9221",
            "9cbb4a39b5344c76a03eba08ea70fd0b",
            "b653750664214689ba000bf84c3d2766",
            "6b950be526f643e6b8d0c9a9edc50317",
            "01609189b1c94d3685ef7707b18f7311",
            "d0009e92007b418d9a3b20f5176d0799",
            "037213458d15457cb3408a9316662b2e",
            "c280847fd57647feb3fb3240ffa66477",
            "088a7cf778f84f86b4f92acc428d787a",
            "1085f8deabc64319a7f7b42dc36fcd4e",
            "3da157789e82483e8d5f91a756236673",
            "24a1cba092974822a629eb86bb3bff98",
            "b73799c314b044789d03103b0828f99d",
            "cd30fee8e6b44a078d0fe3989e84673e",
            "d24286a2088143b4bcf875839f8d42c4",
            "bdf2c40eb37440ca8490ab5356c42d75",
            "66c8b40bbc3f47c796ce4b30bb2ca761",
            "a7f86eb9c3a5490f96ecd15f4b69a876",
            "0f121e2c8dd74621b9fdb444f3c547af",
            "9241592652da4aef8ae4a969743c4a83",
            "96299d770ff84a648f2d6a9c315b6514",
            "a6f7f102d6534e77a57a08652d1fc139",
            "186bf18d014a497bab22134712d33d93",
            "c04687445c66479faa14759e53b58337",
            "38f3d5c0d85444ddb7fd9f3c74184a40",
            "d47f47d12cf841ccb53bbce3d74fb61b",
            "a17e2c1ad08745b68267c09f7132d062",
            "9e70b091a788468799b7b279c46e4eb5",
            "57a6656530774a64ba3bd8ef4f43a758",
            "af62f2a6eb794dc3974dd28f028b6068",
            "6f718aae6e3c457db758816e882012ff",
            "8babff26ca384fbbb6fd7aeca17d4729",
            "0c09a800c18846728a7534551fc2e185",
            "1ada84d2e0d1497683c5f756830303bd",
            "684d0b8d225e441180cb75b5375bad40",
            "ca4b4d53a77d4726abed1d9ade984165",
            "c5a3076053b449dca81ba652c3dc35cf",
            "2319da6b52dd405d8420cb346ab82af3",
            "86170d5cbf4d4176af50583b3a468790",
            "28673511c3fa45caafba2d6dc0a7b77d",
            "a56cf0411ec24214bcc7d928d321523b",
            "d02e71d39f134d2aab4b25b53e219210",
            "850d075111704661a25c1a61c13b1858",
            "7db699befb4d441aa8a64d628392202b"
          ]
        },
        "id": "Va1Jn6mStXhf",
        "outputId": "9ac7f34f-d652-4ac9-eb86-c9b5468a0599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25b9b31146fa4e0eb95b034ca7c607ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c480c76f55e4032950711c34d87fd3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "trainSocc.csv:   0%|          | 0.00/971M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd82c4bbcbec46b583b421fd810591ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "testSocc.csv:   0%|          | 0.00/121M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b1debe136e0475aaf33532d12bf9221",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validationSocc.csv:   0%|          | 0.00/121M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24a1cba092974822a629eb86bb3bff98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/491362 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "186bf18d014a497bab22134712d33d93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/61421 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ada84d2e0d1497683c5f756830303bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/61421 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## QASports Dataset ##\n",
            "Dataset({\n",
            "    features: ['id_qa', 'context_id', 'context', 'question', 'answer', 'context_title', 'context_categories', 'url'],\n",
            "    num_rows: 61421\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "def dataset_switch(choice):\n",
        "    '''Get dataset class'''\n",
        "\n",
        "    if choice == Dataset.SQuAD:\n",
        "        return SQuadDataset()\n",
        "    elif choice == Dataset.AdvQA:\n",
        "        return AdversarialQADataset()\n",
        "    elif choice == Dataset.DuoRC:\n",
        "        return DuoRCDataset()\n",
        "    elif choice == Dataset.QASports:\n",
        "        return QASportsDataset(SPORT)\n",
        "    else:\n",
        "        return \"Invalid dataset\"\n",
        "\n",
        "# Get the dataset\n",
        "dataset = dataset_switch(DATASET)\n",
        "docs = dataset.get_documents()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KA6tLOLhmEF"
      },
      "source": [
        "---\n",
        "## Document Reader\n",
        "\n",
        "In this experiment, we explored three Transformer based models for extractive Question Answering using the [FARM framework](https://github.com/deepset-ai/FARM).\n",
        "* [BERT paper](https://arxiv.org/abs/1810.04805), [implementation](https://huggingface.co/deepset/bert-base-uncased-squad2)\n",
        "* [RoBERTa paper](https://arxiv.org/abs/1907.11692), [implementation](https://huggingface.co/deepset/roberta-base-squad2)\n",
        "* [MiniLM paper](https://arxiv.org/abs/2002.10957), [implementation](https://huggingface.co/deepset/minilm-uncased-squad2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "adb3961745064126be6afe8b08c0d979",
            "df8ea47fe2b642c6babe92be0752a8d6",
            "b2b56248c125414188370280b57b05ba",
            "46cfa13fc7e14dd98688ee1badd6f2cc",
            "f7d2aee91cba43be95b437288acef1ea",
            "cef581d4565240c98c2c0240243fdc2d",
            "ceac1e1baf8949bdbcef4be608a1093d",
            "822743f20b424b789b1ed2d4eef01585",
            "921da5bd68334bb6800729d8929a2ef2",
            "31b23a6762e74103b26ffe24eefb3c3d",
            "40f0c867d1d74c109a49cf3177919d64",
            "7208dd783c484185a98a66a5d7a41ac6",
            "c4e55d09d0f54626965091c9e9d5ba29",
            "bd2c64b4addc48068b2497177b8ac8b7",
            "9b0cc7a280074bdb9788d456a8eceb03",
            "5c60f1c26bfa464b838807d8da2faed8",
            "1c0f08f268bb4ca9863f6ec71dbf89cd",
            "0f6fa271ef8d47a4b7412e90ed3e845a",
            "dd891d3cfc394877a0b8cdc67a1bed97",
            "b949152c143c4a2baf8707963b266170",
            "8685bf8b41214ea7b0cfcbcd2a17a67d",
            "187fbac1ee394629825eedcca4a1c8ed",
            "537ebcbb8e0b427c8bf0b973f681374e",
            "28a45cd8ac3d4fde9e2048c40ce15d7d",
            "f0211192817b45e5830bd0d6d16a7e86",
            "2f8462d708df40fb97d6a377826eccbd",
            "09c732084e354908a10baad6079e6c37",
            "1541b3ef95e1496a899bab874f3ec400",
            "737bc85dbef0483391afb21f3c510449",
            "ae2b319545a84437ba85165719a88002",
            "0a1f0631451b4d828cc0372eaef2afd8",
            "11a64d3a95994ea884425c33dc917102",
            "50d8045e8fad457ead9bdae4ad72e150",
            "5766d375128243d4bb248c7001a2122a",
            "956a44f3cd954f96ba654e224cc2b087",
            "2d5f147eb1bd4bcbb5250be7b3951eae",
            "87c1dd3513b448e3aa775f4ea2aa1d16",
            "5714c59d90af430ea8fc888f0309265e",
            "e369590b5c17488e9a0d800bbd3ef7ba",
            "e8a31cb8b9254816907f8890e6e59dba",
            "7223940c650647b2b894eefa518c821c",
            "51e3052b151244298912e88c411cbf3c",
            "58e015ce6086434591307f565733a464",
            "9e072ebf6608411183b3a59c03cdd671",
            "e6cf07a65b934216965b62bbe43f6cf9",
            "c6b9a1f2d0864fad9924f2d772e7714f",
            "6ab6f26038b046bfbb01501b3871684b",
            "c2b0aa2218df4f8eabe4055cd8e99f0c",
            "45384ded88be4deeb2d7ea2c33303c03",
            "7ead5d9fd8064060bcbb9b97352306a4",
            "a41d1bc9df9c436e9ed0a03b4a3dfd8c",
            "6eb5e222acdd4c97a1bc08ac4ab081c3",
            "e485495d034f45fdaaf7b98cd01c7f0c",
            "e4aa1ccfb2bd4af9b484807d00c9fc7a",
            "bc9abc532db84534bd6ac3e29f3d4d02",
            "ee552d13c87f4112b60750abe27d9d86",
            "f2ed237a87144b61b7c9f57a610a4c42",
            "9f3e296e9b9d4bc18cfe320ca4a59ad5",
            "bc8c5ed713104b929b71632cfdd48874",
            "28fe3494a3814764ac77b79d472b123a",
            "baf2e6e1462c4ce8974c76a9c3693668",
            "f53f01a0e584436492935e1ba79c5d68",
            "39932a62311b418592f8176b778a42f0",
            "a266aa0de9fa447b8b72f38289a9006b",
            "d11f748962cc483d8acf392c8dc65fe1",
            "07fa3b67e9154ec188b0ddad33b30ea4"
          ]
        },
        "id": "p-WqsMnee4Al",
        "outputId": "2badb15e-d03e-432c-c1f3-6aff8b93b47a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adb3961745064126be6afe8b08c0d979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7208dd783c484185a98a66a5d7a41ac6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "537ebcbb8e0b427c8bf0b973f681374e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5766d375128243d4bb248c7001a2122a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6cf07a65b934216965b62bbe43f6cf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee552d13c87f4112b60750abe27d9d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "# Get the reader\n",
        "reader = FARMReader(DOC_READER, use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXMO1L8ojvHl"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "# Build the pipeline\n",
        "pipe = Pipeline()\n",
        "pipe.add_node(component=reader, name='Reader', inputs=['Query'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6DQcu0-liGN",
        "outputId": "45a3daee-c638-40d3-b556-9965c19b0e33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.02s/ Batches]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Query: Who did the Raptors face in the first round of the 2015 Playoffs?'\n",
            "'Answers:'\n",
            "[   <Answer {'answer': 'Algeciras v Novelda', 'type': 'extractive', 'score': 0.13129448890686035, 'context': 'sión B or 2013-14 Tercera División, winner from First round match Algeciras v Novelda, received a bye. Teams from 2013-14 Segunda División gained entr', 'offsets_in_document': [{'start': 114, 'end': 133}], 'offsets_in_context': [{'start': 66, 'end': 85}], 'document_ids': ['337129102467665701580299539122507990947'], 'meta': {'dataset_id': '37677575712103584199147929147757751150', 'title': '2013–14 Copa del Rey | Football Wiki | Fandom', 'dataset_name': 'QASports Dataset'}}>,\n",
            "    <Answer {'answer': 'Rugby Town', 'type': 'extractive', 'score': 0.06147240847349167, 'context': '1 1-1 0-1 2-2 3-1 1-2 4-1 5-1 2-4 2-1 3-0 0-3 2-3 1-1 1-2 4-2 0-1 1-1 Rugby Town 1-1 1-1 3-1 0-1 0-1 2-2 1-2 1-3 1-0 1-2 0-1 0-3 2-0 0-2 1-2 1-2 2-3 1', 'offsets_in_document': [{'start': 1920, 'end': 1930}], 'offsets_in_context': [{'start': 70, 'end': 80}], 'document_ids': ['95241477053108017064231609977342423584'], 'meta': {'dataset_id': '24247270031096109291667961905680889543', 'title': '2016–17 Northern Premier League | Football Wiki | Fandom', 'dataset_name': 'QASports Dataset'}}>,\n",
            "    <Answer {'answer': 'Basford United', 'type': 'extractive', 'score': 0.05545990169048309, 'context': '1-3 3-3 2-5 2-1 1-1 4-0 1-1 1-0 6-1 0-0 3-0 1-1 2-1 1-2 1-1 0-2 0-2 Basford United 3-0 3-3 7-1 2-1 1-2 1-0 2-0 4-2 1-1 2-1 1-0 6-0 2-2 1-0 4-0 1-0 1-1', 'offsets_in_document': [{'start': 544, 'end': 558}], 'offsets_in_context': [{'start': 68, 'end': 82}], 'document_ids': ['95241477053108017064231609977342423584'], 'meta': {'dataset_id': '24247270031096109291667961905680889543', 'title': '2016–17 Northern Premier League | Football Wiki | Fandom', 'dataset_name': 'QASports Dataset'}}>]\n"
          ]
        }
      ],
      "source": [
        "# Testing the pipeline\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "# Querying documents\n",
        "question = \"Who did the Raptors face in the first round of the 2015 Playoffs?\"\n",
        "prediction = pipe.run(query=question, documents=docs[0:10], params={\"Reader\": {\"top_k\": 3}})\n",
        "\n",
        "# Print answer\n",
        "print_answers(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuRBbd0Qndmn"
      },
      "source": [
        "---\n",
        "## Evaluation\n",
        "\n",
        "About the metrics, you can read the [evaluation](https://docs.haystack.deepset.ai/docs/evaluation) web page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DewrQrDklo0e",
        "outputId": "5ec333ad-9186-481d-d852-245c89df5f7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.52 Batches/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 47min 44s, sys: 24.5 s, total: 48min 8s\n",
            "Wall time: 53min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# For testing purposes, running on the first 100 labels\n",
        "# For real evaluation, you must remove the [0:100]\n",
        "eval_labels = dataset.get_validation()\n",
        "eval_docs = [[label.document for label in multi_label.labels] for multi_label in eval_labels]\n",
        "\n",
        "eval_result = pipe.eval(labels=eval_labels, documents=eval_docs, params={\"Reader\": {\"top_k\": NUM_K}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9CUdUzungB_",
        "outputId": "bdaca27b-7459-4435-dfc5-6c7b1fa9844b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Reader': {'exact_match': 0.9953243016424889,\n",
            "            'f1': 0.9953243016424889,\n",
            "            'num_examples_for_eval': 25023.0}}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Get and print the metrics\n",
        "metrics = eval_result.calculate_metrics()\n",
        "pprint(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjuKxz6XLZ9U"
      },
      "outputs": [],
      "source": [
        "# Print a detailed report\n",
        "# pipe.print_eval_report(eval_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yy8zP8RLbI0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gQ2TYqhwhW29"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01609189b1c94d3685ef7707b18f7311": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "037213458d15457cb3408a9316662b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04e0bb63cdf040cbb5ab0443fbe17c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a0d6a59f6241ed920b49c57a7136aa",
            "placeholder": "​",
            "style": "IPY_MODEL_9f9eded686894d9d8a890b3d68db99d1",
            "value": "trainSocc.csv: 100%"
          }
        },
        "07fa3b67e9154ec188b0ddad33b30ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "088a7cf778f84f86b4f92acc428d787a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09c732084e354908a10baad6079e6c37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1f0631451b4d828cc0372eaef2afd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c09a800c18846728a7534551fc2e185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f121e2c8dd74621b9fdb444f3c547af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f6fa271ef8d47a4b7412e90ed3e845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1085f8deabc64319a7f7b42dc36fcd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a0d6a59f6241ed920b49c57a7136aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a64d3a95994ea884425c33dc917102": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1541b3ef95e1496a899bab874f3ec400": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186bf18d014a497bab22134712d33d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c04687445c66479faa14759e53b58337",
              "IPY_MODEL_38f3d5c0d85444ddb7fd9f3c74184a40",
              "IPY_MODEL_d47f47d12cf841ccb53bbce3d74fb61b"
            ],
            "layout": "IPY_MODEL_a17e2c1ad08745b68267c09f7132d062"
          }
        },
        "187fbac1ee394629825eedcca4a1c8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ada84d2e0d1497683c5f756830303bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_684d0b8d225e441180cb75b5375bad40",
              "IPY_MODEL_ca4b4d53a77d4726abed1d9ade984165",
              "IPY_MODEL_c5a3076053b449dca81ba652c3dc35cf"
            ],
            "layout": "IPY_MODEL_2319da6b52dd405d8420cb346ab82af3"
          }
        },
        "1b1debe136e0475aaf33532d12bf9221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cbb4a39b5344c76a03eba08ea70fd0b",
              "IPY_MODEL_b653750664214689ba000bf84c3d2766",
              "IPY_MODEL_6b950be526f643e6b8d0c9a9edc50317"
            ],
            "layout": "IPY_MODEL_01609189b1c94d3685ef7707b18f7311"
          }
        },
        "1b4ac3b0e2b54ac397e95aa4c9da9a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ceca9067e943738b4128c1d17d0793",
            "placeholder": "​",
            "style": "IPY_MODEL_b6839f265ef24761b754471c3a8fb209",
            "value": " 971M/971M [00:11&lt;00:00, 181MB/s]"
          }
        },
        "1c0f08f268bb4ca9863f6ec71dbf89cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f14607562e8485badb5a052721a221b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e18063b84c47f3993489c8c9233503",
            "max": 121454047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad5bd23c565b415ba96e908e08b6defa",
            "value": 121454047
          }
        },
        "2319da6b52dd405d8420cb346ab82af3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a1cba092974822a629eb86bb3bff98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b73799c314b044789d03103b0828f99d",
              "IPY_MODEL_cd30fee8e6b44a078d0fe3989e84673e",
              "IPY_MODEL_d24286a2088143b4bcf875839f8d42c4"
            ],
            "layout": "IPY_MODEL_bdf2c40eb37440ca8490ab5356c42d75"
          }
        },
        "25b9b31146fa4e0eb95b034ca7c607ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ea0d181b9a540fc8cc729b2ef403834",
              "IPY_MODEL_c7e9fea14762476aa2728ab68eae9491",
              "IPY_MODEL_c93f600e6f8a46a9a8b4eee68b1544ff"
            ],
            "layout": "IPY_MODEL_bb72e2fdca80427aae277a5235baa3d0"
          }
        },
        "28673511c3fa45caafba2d6dc0a7b77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a45cd8ac3d4fde9e2048c40ce15d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1541b3ef95e1496a899bab874f3ec400",
            "placeholder": "​",
            "style": "IPY_MODEL_737bc85dbef0483391afb21f3c510449",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "28fe3494a3814764ac77b79d472b123a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5f147eb1bd4bcbb5250be7b3951eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7223940c650647b2b894eefa518c821c",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51e3052b151244298912e88c411cbf3c",
            "value": 898822
          }
        },
        "2f8462d708df40fb97d6a377826eccbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a64d3a95994ea884425c33dc917102",
            "placeholder": "​",
            "style": "IPY_MODEL_50d8045e8fad457ead9bdae4ad72e150",
            "value": " 79.0/79.0 [00:00&lt;00:00, 5.14kB/s]"
          }
        },
        "31b23a6762e74103b26ffe24eefb3c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37be89b7575448c6a581141a1563ac1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f3d5c0d85444ddb7fd9f3c74184a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af62f2a6eb794dc3974dd28f028b6068",
            "max": 61421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f718aae6e3c457db758816e882012ff",
            "value": 61421
          }
        },
        "39932a62311b418592f8176b778a42f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9460f0658148a888ad7265fd28c374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3da157789e82483e8d5f91a756236673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40f0c867d1d74c109a49cf3177919d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45384ded88be4deeb2d7ea2c33303c03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46cfa13fc7e14dd98688ee1badd6f2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b23a6762e74103b26ffe24eefb3c3d",
            "placeholder": "​",
            "style": "IPY_MODEL_40f0c867d1d74c109a49cf3177919d64",
            "value": " 571/571 [00:00&lt;00:00, 52.7kB/s]"
          }
        },
        "50d8045e8fad457ead9bdae4ad72e150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51e3052b151244298912e88c411cbf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "537ebcbb8e0b427c8bf0b973f681374e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28a45cd8ac3d4fde9e2048c40ce15d7d",
              "IPY_MODEL_f0211192817b45e5830bd0d6d16a7e86",
              "IPY_MODEL_2f8462d708df40fb97d6a377826eccbd"
            ],
            "layout": "IPY_MODEL_09c732084e354908a10baad6079e6c37"
          }
        },
        "554b8b933c624e31a8b31f0919e91844": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f019647c68384ee2a8be17776816cde6",
            "placeholder": "​",
            "style": "IPY_MODEL_37be89b7575448c6a581141a1563ac1f",
            "value": " 121M/121M [00:03&lt;00:00, 59.3MB/s]"
          }
        },
        "5714c59d90af430ea8fc888f0309265e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5766d375128243d4bb248c7001a2122a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_956a44f3cd954f96ba654e224cc2b087",
              "IPY_MODEL_2d5f147eb1bd4bcbb5250be7b3951eae",
              "IPY_MODEL_87c1dd3513b448e3aa775f4ea2aa1d16"
            ],
            "layout": "IPY_MODEL_5714c59d90af430ea8fc888f0309265e"
          }
        },
        "57a6656530774a64ba3bd8ef4f43a758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58e015ce6086434591307f565733a464": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a05156d706844f1ad67b656ee3692fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c60f1c26bfa464b838807d8da2faed8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c8b40bbc3f47c796ce4b30bb2ca761": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684d0b8d225e441180cb75b5375bad40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86170d5cbf4d4176af50583b3a468790",
            "placeholder": "​",
            "style": "IPY_MODEL_28673511c3fa45caafba2d6dc0a7b77d",
            "value": "Generating validation split: 100%"
          }
        },
        "69e18063b84c47f3993489c8c9233503": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab6f26038b046bfbb01501b3871684b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb5e222acdd4c97a1bc08ac4ab081c3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e485495d034f45fdaaf7b98cd01c7f0c",
            "value": 456318
          }
        },
        "6b950be526f643e6b8d0c9a9edc50317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1085f8deabc64319a7f7b42dc36fcd4e",
            "placeholder": "​",
            "style": "IPY_MODEL_3da157789e82483e8d5f91a756236673",
            "value": " 121M/121M [00:00&lt;00:00, 230MB/s]"
          }
        },
        "6c480c76f55e4032950711c34d87fd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04e0bb63cdf040cbb5ab0443fbe17c96",
              "IPY_MODEL_d36a52a4d97740b48cee7e39cd0a4eac",
              "IPY_MODEL_1b4ac3b0e2b54ac397e95aa4c9da9a3c"
            ],
            "layout": "IPY_MODEL_c86d153c6b924d96bdd24e5d414cb52e"
          }
        },
        "6ea0d181b9a540fc8cc729b2ef403834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad905b37ff7f4c5ab64d571e822c5dcb",
            "placeholder": "​",
            "style": "IPY_MODEL_9aa7e15974f74c00be51dde405023502",
            "value": "README.md: 100%"
          }
        },
        "6eb5e222acdd4c97a1bc08ac4ab081c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f718aae6e3c457db758816e882012ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7208dd783c484185a98a66a5d7a41ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e55d09d0f54626965091c9e9d5ba29",
              "IPY_MODEL_bd2c64b4addc48068b2497177b8ac8b7",
              "IPY_MODEL_9b0cc7a280074bdb9788d456a8eceb03"
            ],
            "layout": "IPY_MODEL_5c60f1c26bfa464b838807d8da2faed8"
          }
        },
        "7223940c650647b2b894eefa518c821c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "737bc85dbef0483391afb21f3c510449": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c3d7a9f79d449f5a367a273e4d5dab7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db699befb4d441aa8a64d628392202b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ead5d9fd8064060bcbb9b97352306a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822743f20b424b789b1ed2d4eef01585": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850d075111704661a25c1a61c13b1858": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86170d5cbf4d4176af50583b3a468790": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8685bf8b41214ea7b0cfcbcd2a17a67d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c1dd3513b448e3aa775f4ea2aa1d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e015ce6086434591307f565733a464",
            "placeholder": "​",
            "style": "IPY_MODEL_9e072ebf6608411183b3a59c03cdd671",
            "value": " 899k/899k [00:00&lt;00:00, 4.15MB/s]"
          }
        },
        "8babff26ca384fbbb6fd7aeca17d4729": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916b80865a774effa2bb2f8de0d2f8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "921da5bd68334bb6800729d8929a2ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9241592652da4aef8ae4a969743c4a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "956a44f3cd954f96ba654e224cc2b087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e369590b5c17488e9a0d800bbd3ef7ba",
            "placeholder": "​",
            "style": "IPY_MODEL_e8a31cb8b9254816907f8890e6e59dba",
            "value": "vocab.json: 100%"
          }
        },
        "96299d770ff84a648f2d6a9c315b6514": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99be9e05fd7640e7ab7fea1dcaabf3c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa7e15974f74c00be51dde405023502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b0cc7a280074bdb9788d456a8eceb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8685bf8b41214ea7b0cfcbcd2a17a67d",
            "placeholder": "​",
            "style": "IPY_MODEL_187fbac1ee394629825eedcca4a1c8ed",
            "value": " 496M/496M [00:02&lt;00:00, 218MB/s]"
          }
        },
        "9cbb4a39b5344c76a03eba08ea70fd0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0009e92007b418d9a3b20f5176d0799",
            "placeholder": "​",
            "style": "IPY_MODEL_037213458d15457cb3408a9316662b2e",
            "value": "validationSocc.csv: 100%"
          }
        },
        "9e072ebf6608411183b3a59c03cdd671": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e70b091a788468799b7b279c46e4eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3e296e9b9d4bc18cfe320ca4a59ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39932a62311b418592f8176b778a42f0",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a266aa0de9fa447b8b72f38289a9006b",
            "value": 772
          }
        },
        "9f9eded686894d9d8a890b3d68db99d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a17e2c1ad08745b68267c09f7132d062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a266aa0de9fa447b8b72f38289a9006b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a41d1bc9df9c436e9ed0a03b4a3dfd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a56cf0411ec24214bcc7d928d321523b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f7f102d6534e77a57a08652d1fc139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7f86eb9c3a5490f96ecd15f4b69a876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8188b62a3f44a5381e8f4753d27bd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a05156d706844f1ad67b656ee3692fd",
            "placeholder": "​",
            "style": "IPY_MODEL_b5d6dfb3fd2447f4b3391bea51ae5b5e",
            "value": "testSocc.csv: 100%"
          }
        },
        "a9ceca9067e943738b4128c1d17d0793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5bd23c565b415ba96e908e08b6defa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad905b37ff7f4c5ab64d571e822c5dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb3961745064126be6afe8b08c0d979": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df8ea47fe2b642c6babe92be0752a8d6",
              "IPY_MODEL_b2b56248c125414188370280b57b05ba",
              "IPY_MODEL_46cfa13fc7e14dd98688ee1badd6f2cc"
            ],
            "layout": "IPY_MODEL_f7d2aee91cba43be95b437288acef1ea"
          }
        },
        "ae2b319545a84437ba85165719a88002": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af62f2a6eb794dc3974dd28f028b6068": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b56248c125414188370280b57b05ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822743f20b424b789b1ed2d4eef01585",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_921da5bd68334bb6800729d8929a2ef2",
            "value": 571
          }
        },
        "b5d6dfb3fd2447f4b3391bea51ae5b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b653750664214689ba000bf84c3d2766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c280847fd57647feb3fb3240ffa66477",
            "max": 121306631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_088a7cf778f84f86b4f92acc428d787a",
            "value": 121306631
          }
        },
        "b6839f265ef24761b754471c3a8fb209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73799c314b044789d03103b0828f99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c8b40bbc3f47c796ce4b30bb2ca761",
            "placeholder": "​",
            "style": "IPY_MODEL_a7f86eb9c3a5490f96ecd15f4b69a876",
            "value": "Generating train split: 100%"
          }
        },
        "b949152c143c4a2baf8707963b266170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baf2e6e1462c4ce8974c76a9c3693668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb72e2fdca80427aae277a5235baa3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8c5ed713104b929b71632cfdd48874": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d11f748962cc483d8acf392c8dc65fe1",
            "placeholder": "​",
            "style": "IPY_MODEL_07fa3b67e9154ec188b0ddad33b30ea4",
            "value": " 772/772 [00:00&lt;00:00, 80.9kB/s]"
          }
        },
        "bc9abc532db84534bd6ac3e29f3d4d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd2c64b4addc48068b2497177b8ac8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd891d3cfc394877a0b8cdc67a1bed97",
            "max": 496254442,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b949152c143c4a2baf8707963b266170",
            "value": 496254442
          }
        },
        "bdf2c40eb37440ca8490ab5356c42d75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04687445c66479faa14759e53b58337": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e70b091a788468799b7b279c46e4eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_57a6656530774a64ba3bd8ef4f43a758",
            "value": "Generating test split: 100%"
          }
        },
        "c280847fd57647feb3fb3240ffa66477": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b0aa2218df4f8eabe4055cd8e99f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4aa1ccfb2bd4af9b484807d00c9fc7a",
            "placeholder": "​",
            "style": "IPY_MODEL_bc9abc532db84534bd6ac3e29f3d4d02",
            "value": " 456k/456k [00:00&lt;00:00, 3.38MB/s]"
          }
        },
        "c4e55d09d0f54626965091c9e9d5ba29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0f08f268bb4ca9863f6ec71dbf89cd",
            "placeholder": "​",
            "style": "IPY_MODEL_0f6fa271ef8d47a4b7412e90ed3e845a",
            "value": "model.safetensors: 100%"
          }
        },
        "c5a3076053b449dca81ba652c3dc35cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850d075111704661a25c1a61c13b1858",
            "placeholder": "​",
            "style": "IPY_MODEL_7db699befb4d441aa8a64d628392202b",
            "value": " 61421/61421 [00:02&lt;00:00, 19649.38 examples/s]"
          }
        },
        "c6b9a1f2d0864fad9924f2d772e7714f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ead5d9fd8064060bcbb9b97352306a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a41d1bc9df9c436e9ed0a03b4a3dfd8c",
            "value": "merges.txt: 100%"
          }
        },
        "c7e9fea14762476aa2728ab68eae9491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3d7a9f79d449f5a367a273e4d5dab7",
            "max": 3547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f852aceef5cd429eb0e0ff660bef99c7",
            "value": 3547
          }
        },
        "c86d153c6b924d96bdd24e5d414cb52e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93f600e6f8a46a9a8b4eee68b1544ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4360f8966234b39af0333e6e6660703",
            "placeholder": "​",
            "style": "IPY_MODEL_3c9460f0658148a888ad7265fd28c374",
            "value": " 3.55k/3.55k [00:00&lt;00:00, 209kB/s]"
          }
        },
        "ca4b4d53a77d4726abed1d9ade984165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a56cf0411ec24214bcc7d928d321523b",
            "max": 61421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d02e71d39f134d2aab4b25b53e219210",
            "value": 61421
          }
        },
        "cd30fee8e6b44a078d0fe3989e84673e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f121e2c8dd74621b9fdb444f3c547af",
            "max": 491362,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9241592652da4aef8ae4a969743c4a83",
            "value": 491362
          }
        },
        "ceac1e1baf8949bdbcef4be608a1093d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef581d4565240c98c2c0240243fdc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0009e92007b418d9a3b20f5176d0799": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d02e71d39f134d2aab4b25b53e219210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d11f748962cc483d8acf392c8dc65fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24286a2088143b4bcf875839f8d42c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96299d770ff84a648f2d6a9c315b6514",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f7f102d6534e77a57a08652d1fc139",
            "value": " 491362/491362 [00:17&lt;00:00, 30657.07 examples/s]"
          }
        },
        "d36a52a4d97740b48cee7e39cd0a4eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99be9e05fd7640e7ab7fea1dcaabf3c2",
            "max": 970907249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_916b80865a774effa2bb2f8de0d2f8f0",
            "value": 970907249
          }
        },
        "d47f47d12cf841ccb53bbce3d74fb61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8babff26ca384fbbb6fd7aeca17d4729",
            "placeholder": "​",
            "style": "IPY_MODEL_0c09a800c18846728a7534551fc2e185",
            "value": " 61421/61421 [00:02&lt;00:00, 29526.24 examples/s]"
          }
        },
        "d568b297547f439396ef0054339ea15f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd82c4bbcbec46b583b421fd810591ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8188b62a3f44a5381e8f4753d27bd74",
              "IPY_MODEL_1f14607562e8485badb5a052721a221b",
              "IPY_MODEL_554b8b933c624e31a8b31f0919e91844"
            ],
            "layout": "IPY_MODEL_d568b297547f439396ef0054339ea15f"
          }
        },
        "dd891d3cfc394877a0b8cdc67a1bed97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8ea47fe2b642c6babe92be0752a8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef581d4565240c98c2c0240243fdc2d",
            "placeholder": "​",
            "style": "IPY_MODEL_ceac1e1baf8949bdbcef4be608a1093d",
            "value": "config.json: 100%"
          }
        },
        "e369590b5c17488e9a0d800bbd3ef7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e485495d034f45fdaaf7b98cd01c7f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4aa1ccfb2bd4af9b484807d00c9fc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6cf07a65b934216965b62bbe43f6cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6b9a1f2d0864fad9924f2d772e7714f",
              "IPY_MODEL_6ab6f26038b046bfbb01501b3871684b",
              "IPY_MODEL_c2b0aa2218df4f8eabe4055cd8e99f0c"
            ],
            "layout": "IPY_MODEL_45384ded88be4deeb2d7ea2c33303c03"
          }
        },
        "e8a31cb8b9254816907f8890e6e59dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee552d13c87f4112b60750abe27d9d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2ed237a87144b61b7c9f57a610a4c42",
              "IPY_MODEL_9f3e296e9b9d4bc18cfe320ca4a59ad5",
              "IPY_MODEL_bc8c5ed713104b929b71632cfdd48874"
            ],
            "layout": "IPY_MODEL_28fe3494a3814764ac77b79d472b123a"
          }
        },
        "f019647c68384ee2a8be17776816cde6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0211192817b45e5830bd0d6d16a7e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae2b319545a84437ba85165719a88002",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a1f0631451b4d828cc0372eaef2afd8",
            "value": 79
          }
        },
        "f2ed237a87144b61b7c9f57a610a4c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf2e6e1462c4ce8974c76a9c3693668",
            "placeholder": "​",
            "style": "IPY_MODEL_f53f01a0e584436492935e1ba79c5d68",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f4360f8966234b39af0333e6e6660703": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53f01a0e584436492935e1ba79c5d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7d2aee91cba43be95b437288acef1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f852aceef5cd429eb0e0ff660bef99c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
